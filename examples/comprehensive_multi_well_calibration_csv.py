#!/usr/bin/env python3
"""
Test complet pour la calibration multi-puits avec donn√©es CSV.

Ce test valide :
1. Chargement de donn√©es CSV multi-puits
2. Calibration avec plusieurs paires de puits
3. Validation des m√©triques de performance
4. Gestion des erreurs et cas limites
5. Comparaison des r√©sultats entre diff√©rents modes
"""

import sys
import os
import pytest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Add src to path for testing
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from groundwater_estimation import (
    DataLoader, LocalRegionalDecomposition, PerformanceMetrics
)
from groundwater_estimation.core.data_loader import CSVLoader


class TestMultiWellCalibration:
    """Tests complets pour la calibration multi-puits."""
    
    @pytest.fixture
    def sample_csv_data(self):
        """G√©n√®re des donn√©es CSV d'exemple pour les tests."""
        # Cr√©er des donn√©es simul√©es pour 5 puits sur 6 mois
        start_date = datetime(2022, 5, 1)
        end_date = datetime(2022, 10, 31)
        date_range = pd.date_range(start_date, end_date, freq='D')
        
        # Puits de r√©f√©rence avec donn√©es quotidiennes
        reference_wells = ['REF_001', 'REF_002']
        # Puits d'observation avec donn√©es bi-hebdomadaires
        observation_wells = ['OBS_001', 'OBS_002', 'OBS_003']
        
        data = []
        
        # G√©n√©rer donn√©es pour les puits de r√©f√©rence (quotidiennes)
        for well in reference_wells:
            for date in date_range:
                # Niveau d'eau simul√© avec tendance et saisonnalit√©
                days_from_start = (date - start_date).days
                trend = -0.01 * days_from_start  # Tendance d√©croissante
                seasonal = 2 * np.sin(2 * np.pi * days_from_start / 365)
                noise = np.random.normal(0, 0.5)
                water_level = -15 + trend + seasonal + noise
                
                data.append({
                    'Date': date.strftime('%Y-%m-%d'),
                    'Well_ID': well,
                    'Water_Level': round(water_level, 2),
                    'TreatmentUnit': 1,
                    'Type': 'Reference'
                })
        
        # G√©n√©rer donn√©es pour les puits d'observation (bi-hebdomadaires)
        for well in observation_wells:
            # S√©lectionner une date sur deux pour simuler des mesures bi-hebdomadaires
            observation_dates = date_range[::14]
            
            for date in observation_dates:
                days_from_start = (date - start_date).days
                trend = -0.01 * days_from_start
                seasonal = 2 * np.sin(2 * np.pi * days_from_start / 365)
                # Ajouter une variation locale sp√©cifique au puits
                local_variation = np.random.normal(0, 1)
                noise = np.random.normal(0, 0.8)
                water_level = -18 + trend + seasonal + local_variation + noise
                
                data.append({
                    'Date': date.strftime('%Y-%m-%d'),
                    'Well_ID': well,
                    'Water_Level': round(water_level, 2),
                    'TreatmentUnit': 1,
                    'Type': 'Observation'
                })
        
        # Cr√©er le DataFrame
        df = pd.DataFrame(data)
        
        # Sauvegarder temporairement
        csv_path = "tests/temp_multi_well_data.csv"
        os.makedirs(os.path.dirname(csv_path), exist_ok=True)
        df.to_csv(csv_path, index=False)
        
        yield csv_path
        
        # Nettoyer apr√®s les tests
        if os.path.exists(csv_path):
            os.remove(csv_path)
    
    @pytest.fixture
    def data_loader(self, sample_csv_data):
        """Chargeur de donn√©es pour les tests."""
        return DataLoader(sample_csv_data)
    
    @pytest.fixture
    def decomposition(self, data_loader):
        """Instance de d√©composition pour les tests."""
        return LocalRegionalDecomposition(data_loader)
    
    @pytest.fixture
    def performance_metrics(self):
        """Instance de m√©triques de performance pour les tests."""
        return PerformanceMetrics()
    
    def test_data_loading_multi_well(self, data_loader):
        """Test du chargement de donn√©es multi-puits."""
        # V√©rifier que les donn√©es sont charg√©es
        assert data_loader.data is not None
        assert len(data_loader.data) > 0
        
        # V√©rifier la structure des donn√©es
        expected_columns = ['Date', 'Well_ID', 'Water_Level', 'TreatmentUnit', 'Type']
        for col in expected_columns:
            assert col in data_loader.data.columns
        
        # V√©rifier qu'il y a plusieurs puits
        unique_wells = data_loader.data['Well_ID'].unique()
        assert len(unique_wells) >= 5  # Au moins 5 puits
        
        # V√©rifier qu'il y a des puits de r√©f√©rence et d'observation
        well_types = data_loader.data['Type'].unique()
        assert 'Reference' in well_types
        assert 'Observation' in well_types
        
        print(f"‚úÖ Donn√©es charg√©es : {len(data_loader.data)} enregistrements")
        print(f"‚úÖ Puits uniques : {len(unique_wells)}")
        print(f"‚úÖ Types de puits : {list(well_types)}")
    
    def test_calibration_mode_single_pair(self, decomposition, performance_metrics):
        """Test de calibration avec une seule paire de puits."""
        # Tester avec une paire de puits
        results = decomposition.estimate_daily_values(
            target_well="OBS_001",
            reference_well="REF_001",
            treatment_unit=1,
            year=2022,
            mode="calibration"
        )
        
        # V√©rifier la structure des r√©sultats
        assert 'observed' in results
        assert 'estimated' in results
        assert 'dates' in results
        assert 'decomposition' in results
        
        # V√©rifier que les donn√©es ne sont pas vides
        assert len(results['observed']) > 0
        assert len(results['estimated']) > 0
        assert len(results['dates']) > 0
        
        # Calculer les m√©triques de performance
        metrics = performance_metrics.calculate_all_metrics(
            results['observed'], 
            results['estimated']
        )
        
        # V√©rifier que les m√©triques sont calcul√©es
        expected_metrics = ['rmse', 'r2', 'nash_sutcliffe', 'mape', 'bias']
        for metric in expected_metrics:
            assert metric in metrics
            assert isinstance(metrics[metric], (int, float))
        
        print(f"‚úÖ Calibration r√©ussie pour OBS_001/REF_001")
        print(f"‚úÖ M√©triques : RMSE={metrics['rmse']:.3f}, R¬≤={metrics['r2']:.3f}")
    
    def test_calibration_mode_multiple_pairs(self, decomposition, performance_metrics):
        """Test de calibration avec plusieurs paires de puits."""
        # D√©finir les paires √† tester
        well_pairs = [
            ("OBS_001", "REF_001"),
            ("OBS_002", "REF_001"),
            ("OBS_003", "REF_002"),
        ]
        
        all_results = {}
        
        for target_well, reference_well in well_pairs:
            try:
                results = decomposition.estimate_daily_values(
                    target_well=target_well,
                    reference_well=reference_well,
                    treatment_unit=1,
                    year=2022,
                    mode="calibration"
                )
                
                # Calculer les m√©triques
                metrics = performance_metrics.calculate_all_metrics(
                    results['observed'], 
                    results['estimated']
                )
                
                all_results[f"{target_well}_vs_{reference_well}"] = {
                    'results': results,
                    'metrics': metrics
                }
                
                print(f"‚úÖ {target_well} vs {reference_well}: R¬≤={metrics['r2']:.3f}")
                
            except Exception as e:
                print(f"‚ùå Erreur pour {target_well} vs {reference_well}: {e}")
                raise
        
        # V√©rifier que tous les tests ont r√©ussi
        assert len(all_results) == len(well_pairs)
        
        # Analyser la coh√©rence des r√©sultats
        r2_values = [result['metrics']['r2'] for result in all_results.values()]
        print(f"‚úÖ R¬≤ moyen : {np.mean(r2_values):.3f}")
        print(f"‚úÖ R¬≤ min : {np.min(r2_values):.3f}")
        print(f"‚úÖ R¬≤ max : {np.max(r2_values):.3f}")
    
    def test_estimation_mode_consistency(self, decomposition):
        """Test de coh√©rence entre les modes calibration et estimation."""
        # Tester en mode calibration
        cal_results = decomposition.estimate_daily_values(
            target_well="OBS_001",
            reference_well="REF_001",
            treatment_unit=1,
            year=2022,
            mode="calibration"
        )
        
        # Tester en mode estimation
        est_results = decomposition.estimate_daily_values(
            target_well="OBS_001",
            reference_well="REF_001",
            treatment_unit=1,
            year=2022,
            mode="estimation"
        )
        
        # V√©rifier que les r√©sultats sont coh√©rents
        assert len(cal_results['estimated']) == len(est_results['estimated'])
        assert len(cal_results['dates']) == len(est_results['dates'])
        
        # Les estimations devraient √™tre identiques (m√™me donn√©es)
        np.testing.assert_array_almost_equal(
            cal_results['estimated'], 
            est_results['estimated'], 
            decimal=10
        )
        
        print("‚úÖ Coh√©rence entre modes calibration et estimation v√©rifi√©e")
    
    def test_error_handling_invalid_wells(self, decomposition):
        """Test de gestion des erreurs avec des puits invalides."""
        # Tester avec un puits cible inexistant
        with pytest.raises(Exception):
            decomposition.estimate_daily_values(
                target_well="PUITS_INEXISTANT",
                reference_well="REF_001",
                treatment_unit=1,
                year=2022
            )
        
        # Tester avec un puits de r√©f√©rence inexistant
        with pytest.raises(Exception):
            decomposition.estimate_daily_values(
                target_well="OBS_001",
                reference_well="REF_INEXISTANT",
                treatment_unit=1,
                year=2022
            )
        
        print("‚úÖ Gestion des erreurs pour puits invalides v√©rifi√©e")
    
    def test_performance_benchmark(self, decomposition, performance_metrics):
        """Test de performance et benchmark."""
        import time
        
        # Mesurer le temps d'ex√©cution pour plusieurs paires
        well_pairs = [
            ("OBS_001", "REF_001"),
            ("OBS_002", "REF_001"),
            ("OBS_003", "REF_002"),
        ]
        
        execution_times = []
        
        for target_well, reference_well in well_pairs:
            start_time = time.time()
            
            results = decomposition.estimate_daily_values(
                target_well=target_well,
                reference_well=reference_well,
                treatment_unit=1,
                year=2022,
                mode="calibration"
            )
            
            end_time = time.time()
            execution_time = end_time - start_time
            execution_times.append(execution_time)
            
            print(f"‚è±Ô∏è  {target_well} vs {reference_well}: {execution_time:.3f}s")
        
        # V√©rifier que les temps d'ex√©cution sont raisonnables
        avg_time = np.mean(execution_times)
        max_time = np.max(execution_times)
        
        assert avg_time < 5.0  # Moins de 5 secondes en moyenne
        assert max_time < 10.0  # Moins de 10 secondes au maximum
        
        print(f"‚úÖ Performance : Temps moyen = {avg_time:.3f}s, Max = {max_time:.3f}s")
    
    def test_data_quality_validation(self, data_loader):
        """Test de validation de la qualit√© des donn√©es."""
        data = data_loader.data
        
        # V√©rifier qu'il n'y a pas de valeurs manquantes dans les colonnes critiques
        critical_columns = ['Date', 'Well_ID', 'Water_Level']
        for col in critical_columns:
            missing_count = data[col].isnull().sum()
            assert missing_count == 0, f"Valeurs manquantes dans {col}: {missing_count}"
        
        # V√©rifier que les dates sont valides
        data['Date'] = pd.to_datetime(data['Date'])
        assert data['Date'].dt.year.min() >= 2020
        assert data['Date'].dt.year.max() <= 2030
        
        # V√©rifier que les niveaux d'eau sont dans une plage raisonnable
        water_levels = data['Water_Level']
        assert water_levels.min() > -100  # Pas de valeurs extr√™mement n√©gatives
        assert water_levels.max() < 100   # Pas de valeurs extr√™mement positives
        
        print("‚úÖ Validation de la qualit√© des donn√©es r√©ussie")
        print(f"‚úÖ Plage de dates : {data['Date'].min()} √† {data['Date'].max()}")
        print(f"‚úÖ Plage de niveaux d'eau : {water_levels.min():.2f} √† {water_levels.max():.2f}")


def test_integration_workflow():
    """Test d'int√©gration du workflow complet."""
    print("\nüß™ TEST D'INT√âGRATION COMPLET")
    print("=" * 50)
    
    # Ce test sera ex√©cut√© s√©par√©ment pour valider le workflow complet
    # Il peut √™tre utilis√© pour des tests d'int√©gration plus longs
    
    assert True  # Placeholder pour le moment
    print("‚úÖ Test d'int√©gration configur√©")


if __name__ == "__main__":
    # Ex√©cuter les tests si le script est lanc√© directement
    pytest.main([__file__, "-v", "--tb=short"]) 